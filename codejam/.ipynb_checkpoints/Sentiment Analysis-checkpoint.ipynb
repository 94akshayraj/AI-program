{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "from keras import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = 5000\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = vocabulary_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 213,301\n",
      "Trainable params: 213,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embedding_size=32\n",
    "model=Sequential()\n",
    "model.add(Embedding(vocabulary_size, embedding_size, input_length=max_words))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', \n",
    "             optimizer='adam', \n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24936 samples, validate on 64 samples\n",
      "Epoch 1/3\n",
      "24936/24936 [==============================] - 1895s 76ms/step - loss: 0.4386 - acc: 0.7934 - val_loss: 0.3127 - val_acc: 0.8750\n",
      "Epoch 2/3\n",
      "24936/24936 [==============================] - 1348s 54ms/step - loss: 0.3441 - acc: 0.8525 - val_loss: 0.5373 - val_acc: 0.7188\n",
      "Epoch 3/3\n",
      "24936/24936 [==============================] - 1476s 59ms/step - loss: 0.3373 - acc: 0.8659 - val_loss: 0.1846 - val_acc: 0.9688\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3c47152e90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "X_valid, y_valid = X_train[:batch_size], y_train[:batch_size]\n",
    "X_train2, y_train2 = X_train[batch_size:], y_train[batch_size:]\n",
    "\n",
    "model.fit(X_train2, y_train2, validation_data=(X_valid, y_valid), batch_size=batch_size, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ' our experience of the Race franchise, we are fully prepared for bad guys, fast cars, faster gals, dazzling foreign locations, shiny dance-floor moves, locomotives that cost more than a good sized 2BHK flat, supersize mansions, and a thin plot spiced by a twist or two. It is a template, but we are always up for tales with all of the above if they are smart and pacy enough. The trouble with this third part is that it is neither. At two and a half hours, it is a scattershot snoozefest, perking up only when Salman Khan shows up. I never thought, constant reader, that I would say this, but it has to be said: the only time Race 3 revs up is when Bhai and his lady love exchange a bit of banter: the hell-for-leather parts take a back seat. When it came out in 2008, the first Race did something new: it got Bollywood A-listers to be cheerfully amoral. Not immoral, that one was old. Being plain bad could lead to redemption. And very often did. But big stars playing characters who were greedy, vicious and amoral, without a single mitigating reason (sick mother, tragic sister and so on), was something that got us to sit up and pay attention.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id = imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in x.split():\n",
    "    if i in word2id.keys():\n",
    "        lst.append(word2id[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  260,   582,     4,     1,    72,    23,  1311,  2845,    15,\n",
       "           75,   699,  4288,  6200,  2186,  8817,    12,  2319,    50,\n",
       "           71,     3,    49,  6367, 51237,     2,     3,  1520,   111,\n",
       "        18502,    31,     3,  1006,    39,     6,     3,    18,    72,\n",
       "           23,   207,    53,    15,  2950,    16,    29,     4,     1,\n",
       "          749,    45,    33,    23,  1390,     2, 72169,  1110,    16,\n",
       "           11,   837,   170,     6,    12,     9,     6,   104,     2,\n",
       "            3,   317,     9,     6,     3, 36038, 62118,    53,    61,\n",
       "           51,   284,   112,  1810,    12,    59,   132,    18,     9,\n",
       "           44,     5,    27,     1,    61,    55,   339, 50105,    53,\n",
       "            6,    51,     2,    24,   758,   116,  5113,     3,   224,\n",
       "            4,     1,   528,   190,     3,   142,     9,   382,    43,\n",
       "            8,     1,    83,   119,   139,     9,   185,     5,    27,\n",
       "        17321,    12,    28,    13,  1041,    75,    97,   482,     5,\n",
       "           52,   397,   191,   378,   392,   102,    34,    68,  3836,\n",
       "            2,   206,     3,   683, 66258,   279,  1576,   796,     2,\n",
       "           35,    13,   139,    12,   185,   175,     5,   867,    53,\n",
       "            2,   987]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndar = np.array([lst])\n",
    "ndar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_test = sequence.pad_sequences(ndar, maxlen=max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 500)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "indices[0,357] = 6200 is not in [0, 5000)\n\t [[Node: embedding_1/embedding_lookup = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@embedding_1/embeddings\"], validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](embedding_1/embeddings/read, embedding_1/Cast)]]\n\nCaused by op u'embedding_1/embedding_lookup', defined at:\n  File \"/opt/anaconda2/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/opt/anaconda2/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/opt/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/opt/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/opt/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/opt/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py\", line 1064, in start\n    handler_func(fd_obj, events)\n  File \"/opt/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/opt/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/opt/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/opt/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/opt/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/opt/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/opt/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/anaconda2/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/opt/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2714, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2818, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/opt/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2878, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-4-8a4b5a940ec0>\", line 3, in <module>\n    model.add(Embedding(vocabulary_size, embedding_size, input_length=max_words))\n  File \"/opt/anaconda2/lib/python2.7/site-packages/keras/engine/sequential.py\", line 166, in add\n    layer(x)\n  File \"/opt/anaconda2/lib/python2.7/site-packages/keras/engine/base_layer.py\", line 460, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/opt/anaconda2/lib/python2.7/site-packages/keras/layers/embeddings.py\", line 139, in call\n    out = K.gather(self.embeddings, inputs)\n  File \"/opt/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py\", line 1225, in gather\n    return tf.nn.embedding_lookup(reference, indices)\n  File \"/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/embedding_ops.py\", line 325, in embedding_lookup\n    transform_fn=None)\n  File \"/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/embedding_ops.py\", line 150, in _embedding_lookup_and_transform\n    result = _clip(_gather(params[0], ids, name=name), ids, max_norm)\n  File \"/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/embedding_ops.py\", line 54, in _gather\n    return array_ops.gather(params, ids, name=name)\n  File \"/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py\", line 2585, in gather\n    params, indices, validate_indices=validate_indices, name=name)\n  File \"/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1864, in gather\n    validate_indices=validate_indices, name=name)\n  File \"/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): indices[0,357] = 6200 is not in [0, 5000)\n\t [[Node: embedding_1/embedding_lookup = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@embedding_1/embeddings\"], validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](embedding_1/embeddings/read, embedding_1/Cast)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-a2877317cc75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1170\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1172\u001b[0;31m                                             steps=steps)\n\u001b[0m\u001b[1;32m   1173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/opt/anaconda2/lib/python2.7/site-packages/keras/engine/training_arrays.pyc\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2665\u001b[0m                     \u001b[0;34m'In order to feed symbolic tensors to a Keras model '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m                     'in TensorFlow, you need tensorflow 1.8 or higher.')\n\u001b[0;32m-> 2667\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m_legacy_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2647\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2648\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2649\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2650\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1363\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: indices[0,357] = 6200 is not in [0, 5000)\n\t [[Node: embedding_1/embedding_lookup = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@embedding_1/embeddings\"], validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](embedding_1/embeddings/read, embedding_1/Cast)]]\n\nCaused by op u'embedding_1/embedding_lookup', defined at:\n  File \"/opt/anaconda2/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/opt/anaconda2/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/opt/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/opt/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/opt/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/opt/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py\", line 1064, in start\n    handler_func(fd_obj, events)\n  File \"/opt/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/opt/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/opt/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/opt/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/opt/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/opt/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/opt/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/anaconda2/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/opt/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2714, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2818, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/opt/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2878, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-4-8a4b5a940ec0>\", line 3, in <module>\n    model.add(Embedding(vocabulary_size, embedding_size, input_length=max_words))\n  File \"/opt/anaconda2/lib/python2.7/site-packages/keras/engine/sequential.py\", line 166, in add\n    layer(x)\n  File \"/opt/anaconda2/lib/python2.7/site-packages/keras/engine/base_layer.py\", line 460, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/opt/anaconda2/lib/python2.7/site-packages/keras/layers/embeddings.py\", line 139, in call\n    out = K.gather(self.embeddings, inputs)\n  File \"/opt/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py\", line 1225, in gather\n    return tf.nn.embedding_lookup(reference, indices)\n  File \"/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/embedding_ops.py\", line 325, in embedding_lookup\n    transform_fn=None)\n  File \"/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/embedding_ops.py\", line 150, in _embedding_lookup_and_transform\n    result = _clip(_gather(params[0], ids, name=name), ids, max_norm)\n  File \"/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/embedding_ops.py\", line 54, in _gather\n    return array_ops.gather(params, ids, name=name)\n  File \"/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py\", line 2585, in gather\n    params, indices, validate_indices=validate_indices, name=name)\n  File \"/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1864, in gather\n    validate_indices=validate_indices, name=name)\n  File \"/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"/opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): indices[0,357] = 6200 is not in [0, 5000)\n\t [[Node: embedding_1/embedding_lookup = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@embedding_1/embeddings\"], validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](embedding_1/embeddings/read, embedding_1/Cast)]]\n"
     ]
    }
   ],
   "source": [
    "model.predict(word_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
