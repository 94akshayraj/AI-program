{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/spacslug/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data with 25000 train samples and 25000 test samples\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = 5000\n",
    "\n",
    "(X_train,y_train),(X_test,y_test) = imdb.load_data(num_words=vocabulary_size)\n",
    "print('loaded data with {} train samples and {} test samples'.format(len(X_train),len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 500\n",
    "\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_words)\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "embedding_size=32\n",
    "model=Sequential()\n",
    "model.add(Embedding(vocabulary_size, embedding_size, input_length=max_words))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', \n",
    "             optimizer='adam', \n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_epochs = 3\n",
    "\n",
    "X_valid, y_valid = X_train[:batch_size], y_train[:batch_size]\n",
    "X_train2, y_train2 = X_train[batch_size:], y_train[batch_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24936 samples, validate on 64 samples\n",
      "Epoch 1/3\n",
      "24936/24936 [==============================] - 279s 11ms/step - loss: 0.4487 - acc: 0.7844 - val_loss: 0.2203 - val_acc: 0.9531\n",
      "Epoch 2/3\n",
      "24936/24936 [==============================] - 303s 12ms/step - loss: 0.2851 - acc: 0.8867 - val_loss: 0.4572 - val_acc: 0.7812\n",
      "Epoch 3/3\n",
      "24936/24936 [==============================] - 321s 13ms/step - loss: 0.6430 - acc: 0.6769 - val_loss: 0.6494 - val_acc: 0.6406\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x181d503950>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train2, y_train2, validation_data=(X_valid, y_valid), batch_size=batch_size, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test accuracy:', 0.59876)\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for long() with base 10: 'a'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-1faf23c36d84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'at some point well down the road in Race 3, as I slumped low in my chair, passing the time, a character said, ‘I’ve got a bad feeling about this’. Ding dong, news flash: we could have told her that right in the beginning. Given our experience of the Race franchise, we are fully prepared for bad guys, fast cars, faster gals, dazzling foreign locations, shiny dance-floor moves, locomotives that cost more than a good sized 2BHK flat, supersize mansions, and a thin plot spiced by a twist or two. It’s a template, but we are always up for tales with all of the above if they are smart and pacy enough. The trouble with this third part is that it is neither. At two and a half hours, it is a scattershot snoozefest, perking up only when Salman Khan shows up. I never thought, constant reader, that I’d say this, but it has to be said: the only time Race 3 revs up is when Bhai and his lady love exchange a bit of banter: the hell-for-leather parts take a back seat. When it came out in 2008, the first Race did something new: it got Bollywood A-listers to be cheerfully amoral. Not immoral, that one was old. Being plain bad could lead to redemption. And very often did. But big stars playing characters who were greedy, vicious and amoral, without a single mitigating reason (sick mother, tragic sister and so on), was something that got us to sit up and pay attention. It helped that Abbas-Mustan, the two brothers who made Race, knew when to keep things down and dirty and when to break into song. Race 2, also helmed by them, trotted out the same formula, but by the then, it already felt stale. I love supernatural dramas Race 3 is nothing but a recycled bin of too many car chases, explosions, buffed up characters strutting in slo-mo, and wilted lines. The same character who had a ‘bad feeling’, also uses the word ‘so tacky’. Well, what else would you call a film which doesn’t do justice to its finest asset, Anil Kapoor? The superbly fit Kapoor is a left-over from the previous Race flicks, and he was an absolute hoot in both.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# words = words.split()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/spacslug/anaconda2/lib/python2.7/site-packages/keras_preprocessing/sequence.pyc\u001b[0m in \u001b[0;36mpad_sequences\u001b[0;34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;31m# check `trunc` has expected shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mtrunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0msample_shape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             raise ValueError('Shape of sample %s of sequence at position %s '\n",
      "\u001b[0;32m/Users/spacslug/anaconda2/lib/python2.7/site-packages/numpy/core/numeric.pyc\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m     \"\"\"\n\u001b[0;32m--> 492\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for long() with base 10: 'a'"
     ]
    }
   ],
   "source": [
    "words = 'at some point well down the road in Race 3, as I slumped low in my chair, passing the time, a character said, ‘I’ve got a bad feeling about this’. Ding dong, news flash: we could have told her that right in the beginning. Given our experience of the Race franchise, we are fully prepared for bad guys, fast cars, faster gals, dazzling foreign locations, shiny dance-floor moves, locomotives that cost more than a good sized 2BHK flat, supersize mansions, and a thin plot spiced by a twist or two. It’s a template, but we are always up for tales with all of the above if they are smart and pacy enough. The trouble with this third part is that it is neither. At two and a half hours, it is a scattershot snoozefest, perking up only when Salman Khan shows up. I never thought, constant reader, that I’d say this, but it has to be said: the only time Race 3 revs up is when Bhai and his lady love exchange a bit of banter: the hell-for-leather parts take a back seat. When it came out in 2008, the first Race did something new: it got Bollywood A-listers to be cheerfully amoral. Not immoral, that one was old. Being plain bad could lead to redemption. And very often did. But big stars playing characters who were greedy, vicious and amoral, without a single mitigating reason (sick mother, tragic sister and so on), was something that got us to sit up and pay attention. It helped that Abbas-Mustan, the two brothers who made Race, knew when to keep things down and dirty and when to break into song. Race 2, also helmed by them, trotted out the same formula, but by the then, it already felt stale. I love supernatural dramas Race 3 is nothing but a recycled bin of too many car chases, explosions, buffed up characters strutting in slo-mo, and wilted lines. The same character who had a ‘bad feeling’, also uses the word ‘so tacky’. Well, what else would you call a film which doesn’t do justice to its finest asset, Anil Kapoor? The superbly fit Kapoor is a left-over from the previous Race flicks, and he was an absolute hoot in both.'\n",
    "# words = words.split()\n",
    "words = sequence.pad_sequences(words, maxlen=max_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=[]\n",
    "for i in words:\n",
    "    if i in word.keys():\n",
    "#         print ()\n",
    "        lst.append(word[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst =np.array(lst).reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_test = sequence.pad_sequences(lst, maxlen=max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = model.predict(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
